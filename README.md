# NLP_news_group_data

## Summary
* The project takes the 20Newsgroup dataset, which contains 20,000 newsgroup documents partitioned between 20 newsgroups. 

* We preprocess news data and imagine the term-recurrence dispersion. Then we vectorize these archives utilizing BoW, TF-IDF, LDA, Word2Vec, and Doc2Vec models.

* Once the vector representation of the archives is obtained, we perform clustering using the K-Means Model. We used the gensim module for training models and use sklearn module to perform clustering and supervised models.
