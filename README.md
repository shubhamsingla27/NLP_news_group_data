# NLP_news_group_data
The project takes the 20Newsgroup dataset, which contains 20,000 newsgroup documents partitioned between 20 newsgroups. 
We preprocess it and imagine the term-recurrence dispersion. Then we vectorize these archives utilizing BoW, TF-IDF, LDA, Word2Vec, and Doc2Vec models. 
Once the vector representation of the archives is obtained, we perform clustering using the K-Means Model. We mainly use the gensim module for training models and use sklearn module to perform clustering and supervised models.
